---
title: "Bike Share Analysis"
author: "Zsolt Oláh"
date: "2025-12-21"
output:
  pdf_document: default
  html_document: default
---

## 0. Scenario

<div style="text-align: justify;">

I am a junior data analyst on the marketing analytics team at a bike‑share company in Chicago. The director of marketing believes the company’s future success depends on maximizing the number of annual memberships. Therefore, our team wants to understand how casual riders and annual members use the bikes differently. Using these insights, we will design a new marketing strategy to convert casual riders into annual members. Before moving forward, company executives must approve our recommendations, so they need to be supported by compelling data insights and professional data visualizations.

## 1. Ask

The first step of the analysis is to define the problem we are trying to solve. There is a question that should be answered by the end of the project. As mentioned above, this question is:

**How do annual members and casual riders use the bikes differently?**

And based on the answer, we should provide three recommendations that address the following question:

**What actions can turn casual riders into annual members?**

### 2. Prepare

The dataset is publicly available and can be accessed at this 
[link](https://divvy-tripdata.s3.amazonaws.com/index.html). The data is provided in several segmented formats, and for this analysis we will download the monthly segmented files.

It is important to perform a **ROCCC analysis** on the dataset:

- **R – Reliable:** The dataset is generated by the automated electronic rental system, so it is considered reliable. 
- **O – Original:** The data is collected directly by the bike‑share company, making it an original source.
- **C – Comprehensive:** The dataset contains sufficient information to answer our question, such as user gender and age, ride date and time, and whether the rider is a casual user or a subscriber. 
- **C – Current:** The analysis is conducted in 2025, the data is relevant because it was collected during the previous 12 month (202412-202511) 
- **C – Cited:** The dataset originates from the company’s own data collection.

After reviewing the dataset, it becomes clear that we should merge the monthly files into a single dataset so that we can process the data in a simple, uniform manner.

## 3. Process

- Load the required libraries.

- Import the downloaded dataset. Although all 12 CSV files appear to share the same structure, we enforce consistent formatting by extracting column specifications from the first file and applying them to all subsequent imports to ensure structural integrity before merging.

- Create and save a small sample dataset for external investigation (e.g., using LLMs to explore and get ideas regarding structure, cleaning, and data integrity).

- Generate several new columns derived from existing fields to provide additional analytical perspectives.

- Check for missing values, examine where they occur, and remove rows containing null values in columns essential to the analysis.

- Inspect numeric columns for outliers and remove invalid entries (e.g., negative durations or unrealistic average speeds).

- Review datetime columns for anomalies; no outliers were detected.

- Convert categorical columns to factors and inspect their levels to identify potential misspellings or inconsistencies; no issues were found.

- Check for duplicated rows: none were present.

```{r Library Setup, warning=FALSE, include=FALSE}
library(tidyverse)
library(purrr)
library(lubridate)
library(ggplot2)
library(geosphere)
library(patchwork)
library(stringr)

# Use the conflicted package to manage conflicts
library(conflicted)

# Set dplyr::filter and dplyr::lag as the default choices
conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")

```

```{r Load the dataset, warning=FALSE, include=FALSE}
## Extract column specifications from one reference file to enforce consistent types
spec <- read_csv("Original Raw Data/202412-divvy-tripdata.csv", show_col_types = FALSE) %>% 
  spec()

# List all Divvy CSV files in the subfolder "Original Raw Data/"
files <- list.files("Original Raw Data", pattern = "divvy-tripdata\\.csv$", full.names = TRUE)

# Read all files using the same column spec and combine into one dataframe
all_trips <- files %>%
  set_names() %>%                      # Keep filenames as list names
  map_df(~ read_csv(.x, col_types = spec))
```

```{r Save sample dataset, warning=FALSE, include=FALSE}
# Select the first 100 rows from the all_trips dataset
# Goal: create a smaller sample that's easier to inspect or share outside RStudio
sample_trips <- all_trips %>% slice_head(n = 100)

# Save the sample dataset as a CSV file for external investigation
write_csv(sample_trips, "sample_trips.csv")
```


```{r Feature engineering, warning=FALSE, include=FALSE}
all_trips <- all_trips %>%
  mutate(
    # Calendar features
    quarter = quarter(started_at),          # 1–4
    month   = month(started_at),            # 1–12
    week    = isoweek(started_at),          # 1–53 (ISO standard)
    wday    = wday(started_at, week_start = 1),  # 1=Monday … 7=Sunday
    weekday_flag = if_else(wday <= 5, "weekday", "weekend"),
    dayhour = hour(started_at),                # 0–23
    
    # Duration in hours
    duration_hour = round(as.numeric(ended_at - started_at, units = "secs") / 3600, 4),

    # Distance in kilometers (Haversine)
    distance_km = round(
      distHaversine(
        cbind(start_lng, start_lat),
        cbind(end_lng,   end_lat)
      ) / 1000,
      4
    ),
    
    # Average speed in km/h
    avg_speed_kmh = round(distance_km / duration_hour, 2)
  )

```

```{r Check for null values, warning=FALSE, include=FALSE}
# Investigate the presence of null values in each column individually.
colSums(is.na(all_trips))
```


```{r Remove null values, warning=FALSE, include=FALSE}
# Remove only those rows containing null values in columns that are essential for our analysis.
all_trips <- all_trips %>%
  filter(
    !is.na(end_lat),
    !is.na(end_lng),
    !is.na(distance_km),
    !is.na(avg_speed_kmh)
  )
```

```{r Chek numerics for outliers, warning=FALSE, include=FALSE}
# Check numeric columns for outliers.
all_trips %>% 
  select(where(is.numeric)) %>% 
  summary()
```

```{r Remove numeric outliers, warning=FALSE, include=FALSE}
# Remove trips with non-positive duration
all_trips <- all_trips %>% 
  filter(duration_hour > 0)

# Filter out unrealistic speeds
all_trips <- all_trips %>% 
  filter(avg_speed_kmh > 0 & avg_speed_kmh < 35)

# Filter out statistically distorting distances
Q1 <- quantile(all_trips$distance_km, 0.25, na.rm = TRUE)
Q3 <- quantile(all_trips$distance_km, 0.75, na.rm = TRUE)
IQR_value <- IQR(all_trips$distance_km, na.rm = TRUE)

lower_bound <- Q1 - 1.5 * IQR_value
upper_bound <- Q3 + 1.5 * IQR_value

all_trips <- all_trips %>% 
  filter(distance_km >= lower_bound, distance_km <= upper_bound)

# Filter out statistically distorting duration hours
Q1 <- quantile(all_trips$duration_hour, 0.25, na.rm = TRUE)
Q3 <- quantile(all_trips$duration_hour, 0.75, na.rm = TRUE)
IQR_value <- IQR(all_trips$duration_hour, na.rm = TRUE)

lower_bound <- Q1 - 1.5 * IQR_value
upper_bound <- Q3 + 1.5 * IQR_value

all_trips <- all_trips %>% 
  filter(duration_hour >= lower_bound, duration_hour <= upper_bound)
```

```{r Check datetimes for outliers, warning=FALSE, include=FALSE}
# Check datetime columns for outliers.
all_trips %>% 
  select(where(is.POSIXt)) %>% 
  summary()
```

```{r Check factors for consistency, warning=FALSE, include=FALSE}
# Convert category fields to factors and inspect their unique values
# to verify category consistency and catch any misspellings
all_trips <- all_trips %>% 
  mutate(rideable_type = as.factor(rideable_type)) %>% 
  mutate(member_casual = as.factor(member_casual)) %>% 
  mutate(weekday_flag = as.factor(weekday_flag))

# Display the unique levels for all factor columns
all_trips %>% 
  select(where(is.factor)) %>% 
  map(unique)
```


```{r Check duplicate rows, eval=FALSE, include=FALSE}
# Count how many duplicate rows exist in the all_trips dataset
sum(duplicated(all_trips))
```

```{r Save sample cleaned dataset, warning=FALSE, include=FALSE}
# Select the first 100 rows from the cleanedall_trips dataset and save it
sample_trips_cleaned <- all_trips %>% slice_head(n = 100)

write_csv(sample_trips_cleaned, "sample_trips_cleand.csv")
```

## 4. Analysis and Share

Because the ultimate goal is to convert casual riders into annual members, it is important to first evaluate whether the casual rider segment is large enough to justify targeted marketing efforts. To do this, we begin by examining the proportion of rides coming from each user group.

It can be stated confidently that the target segment is large enough to have potential to get more revenue from turning them to annual members so we proceed the analysis.

```{r Counts per usert type, echo=FALSE, warning=FALSE, fig.height=3, fig.width=4.5, fig.align='center'}
library(scales)

# Count rides by user type
count_by_type <- all_trips %>% 
  count(member_casual) %>% 
  mutate(
    percent = n / sum(n) * 100,
    n_millions = paste0(format(round(n / 1e6, 2), nsmall = 2), "M")
  )

# Column chart
ggplot(count_by_type, aes(x = member_casual, y = n, fill = member_casual)) +
  geom_col(width = 0.6, color = "white") +
  scale_y_continuous(
    labels = function(x) paste0(round(x / 1e6, 2), "M"),
    expand = expansion(mult = c(0, 0.15))
  ) +
  geom_text(
    aes(label = paste0(n_millions, " (", round(percent, 1), "%)")),
    vjust = -0.5,
    color = "black",
    size = 4
  ) +
  labs(
    title = "Ride Distribution by User Type",
    x = "User Type",
    y = "Number of Rides (Millions)"
  ) +
  scale_fill_manual(values = c("member" = "steelblue", "casual" = "tomato")) +
  theme_minimal(base_size = 12) +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", hjust = 0.5)
  )
```
Next, we check whether there is any difference in bike types used between the two user groups.As the image shows, there is only a minimal difference: casual users tend to use electric bikes slightly more often than members.

```{r Percentage per Bike Types, echo=FALSE, fig.height=3, fig.width=4.5, fig.align='center', warning=FALSE}
# Prepare data: count rides by weekday_flag and user type
rideable_type_summary <- all_trips %>% 
  count(rideable_type, member_casual) %>% 
  group_by(rideable_type) %>% 
  mutate(
    percent = n / sum(n) * 100,
    percent_label = paste0(round(percent, 0), "%")
  )

# Stacked percentage bar chart
ggplot(rideable_type_summary, aes(x = rideable_type, y = percent, fill = member_casual)) +
  geom_col(color = "white", width = 0.7) +
  geom_text(
    aes(label = percent_label),
    position = position_stack(vjust = 0.5),
    color = "white",
    size = 4
  ) +
  scale_fill_manual(values = c("member" = "steelblue", "casual" = "tomato")) +
  scale_y_continuous(labels = function(x) paste0(x, "%")) +
  labs(
    title = str_wrap("Classic vs. Electric Bike Usage by User Type", width = 40),
    x = ("Bike Type"),
    y = "Percentage of Rides",
    fill = "User Type"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    legend.position = "top"
  )
```


The following two charts show the usage patterns across the year and the week. The yearly pattern is quite similar for the two user groups, but the weekly trends reveal the real difference: 

- **member riders** use the service more during the first four days of the week, after which usage declines toward the weekend,
- meanwhile, **casual riders** hardly use the service during the first three days of the week, and their usage increases steadily as the weekend approaches, peaking on Saturday.

```{r Monthly ride usage, echo=FALSE, warning=FALSE, fig.height=3, fig.width=4.5, fig.align='center'}
# Prepare data: count rides by month of the year + user type
monthly_summary <- all_trips %>% 
  count(month, member_casual) %>% 
  group_by(member_casual) %>% 
  mutate(
    percent = n / sum(n) * 100
  )

# Line chart
ggplot(monthly_summary, aes(x = month, y = n, color = member_casual)) +
  geom_line(size = 1.3) +
  geom_point(size = 2) +
  scale_color_manual(values = c("member" = "steelblue","casual" = "tomato")) +
  scale_x_continuous(breaks = 1:12, labels = month.abb) +
  scale_y_continuous(
    labels = scales::label_number(scale = 1e-6, suffix = "M"),
    expand = expansion(mult = c(0, 0.05))
  ) +
  labs(
    title = str_wrap("Monthly Ride Usage Pattern by User Type", width = 40),
    x = "Month of Year",
    y = "Number of Rides (Millions)",
    color = "User Type"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    legend.position = "top"
  )
```
```{r Daily ride usage, echo=FALSE, warning=FALSE, fig.height=3, fig.width=4.5, fig.align='center'}
# Prepare data: count rides by day of the week + user type
weekdaily_summary <- all_trips %>% 
  count(wday, member_casual) %>% 
  group_by(member_casual) %>% 
  mutate(
    percent = n / sum(n) * 100
  )

# Line chart
ggplot(weekdaily_summary, aes(x = wday, y = n, color = member_casual)) +
  geom_line(size = 1.3) +
  geom_point(size = 2) +
  scale_color_manual(values = c("member" = "steelblue","casual" = "tomato")) +
  scale_x_continuous(breaks = 1:7, labels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")) +
  scale_y_continuous(
    labels = scales::label_number(scale = 1e-6, suffix = "M"),
    expand = expansion(mult = c(0, 0.05))
  ) +
  labs(
    title = str_wrap("Day of the Week Ride Usage Pattern by User Type", width = 40),
    x = "Day of the Week",
    y = "Number of Rides (Millions)",
    color = "User Type"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    legend.position = "top"
  )
```

The hourly chart shows another difference between the two user groups:

- **the usage pattern of member riders has two peaks**: the first in the morning from 7:30 to 8:30, and the second in the afternoon from 16:30 to 17:30. This clearly indicates that they use the bikes for commuting,
- **although casual riders also show these two peaks, they are far smaller than those of the members**.

 
```{r Hourly ride usage, echo=FALSE, warning=FALSE, fig.height=3, fig.width=4.5, fig.align='center'}
# Prepare data: count rides by hour of the day + user type
hourly_summary <- all_trips %>% 
  count(dayhour, member_casual) %>% 
  group_by(member_casual) %>% 
  mutate(
    percent = n / sum(n) * 100
  )

# Line chart
ggplot(hourly_summary, aes(x = dayhour, y = n, color = member_casual)) +
  geom_line(size = 1.3) +
  geom_point(size = 2) +
  scale_color_manual(values = c("member" = "steelblue","casual" = "tomato")) +
  scale_x_continuous(breaks = 0:23, labels = sprintf("%d:00", 0:23)) +
  scale_y_continuous(
    labels = scales::label_number(scale = 1e-6, suffix = "M"),
    expand = expansion(mult = c(0, 0.05))
  ) +
  labs(
    title = str_wrap("Hourly Ride Usage Pattern by User Type", width = 40),
    x = "Hour of Day",
    y = "Number of Rides (Millions)",
    color = "User Type"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    legend.position = "top",
  axis.text.x = element_text(angle = 90, hjust = 1)
  )
```

The next two charts show the distribution of ride distances and durations by user group. These visuals clearly indicate that, overall, there is no significant difference between the two patterns: distribution of both user groups are right‑skewed and their peaks occur in roughly the same place.

```{r Distribution of ride distances, echo=FALSE, warning=FALSE, fig.height=3, fig.width=4.5, fig.align='center'}
ggplot(all_trips, aes(x = distance_km, fill = member_casual)) +
  geom_histogram(
    alpha = 0.7,
    bins = 50,
    color = "white"
  ) +
  scale_fill_manual(values = c("member" = "steelblue", "casual" = "tomato")) +
  scale_y_continuous(
    labels = scales::label_number(scale = 1e-3, suffix = "K"),
    expand = expansion(mult = c(0, 0.05))
  ) +
  facet_wrap(~member_casual, ncol = 1) +
  labs(
    title = str_wrap("Distribution of Ride Distances by User Type", width = 40),
    x = "Distance (km)",
    y = "Number of Rides"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    legend.position = "none",
    strip.text = element_text(face = "bold", size = 14)
  )
```
```{r Distribution of ride durations, echo=FALSE, warning=FALSE, fig.height=3, fig.width=4.5, fig.align='center'}
ggplot(all_trips, aes(x = duration_hour, fill = member_casual)) +
  geom_histogram(
    alpha = 0.7,
    bins = 50,
    color = "white"
  ) +
  scale_fill_manual(values = c("member" = "steelblue", "casual" = "tomato")) +
  scale_y_continuous(
    labels = scales::label_number(scale = 1e-3, suffix = "K"),
    expand = expansion(mult = c(0, 0.05))
  ) +
  facet_wrap(~member_casual, ncol = 1, scales = "free_y") +
  labs(
    title = str_wrap("Distribution of Ride Durations by User Type", width = 40),
    x = "Duration (hour)",
    y = "Number of Rides"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    legend.position = "none",
    strip.text = element_text(face = "bold", size = 14)
  )
```

## 5. Act

Based on the analysis above, these are our three recommendations for possible marketing actions to turn casual riders into annual members, focusing on the differences in their usage behavior:

- Since casual riders mainly use our service on weekends, we can develop a new yearly subscription type for weekend users. With this subscription, users would receive discounts on weekend days.
- The analysis also revealed another major usage pattern: users who ride our bikes for commuting on weekdays. For retention purposes, it is worth considering a second special subscription type for them, offering discounts on weekdays.
- We can plan a marketing campaign with a physical presence at docking stations to promote these new subscription types. To increase the efficiency of this campaign, it is worth conducting further analysis to identify whether there are preferred starting or ending docking stations, possibly segmented by the two user groups.

</div>